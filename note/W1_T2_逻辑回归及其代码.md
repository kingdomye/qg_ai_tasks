# 逻辑回归及其代码

## 逻辑回归介绍

逻辑回归（Logistic Regression）是一种经典的分类算法，尽管名字中有“回归”二字，但它主要用于解决**二分类问题**，即预测的目标变量是二元的（如0或1、是或否、正类或负类）。逻辑回归通过逻辑函数（Sigmoid函数）将线性回归的输出映射到(0, 1)区间，从而将问题转化为概率预测。

**【逻辑回归模型】**

```math
P(y=1|x)=\frac{1}{1+e^{-\mathbf{ \omega ^{T}x}}} 
```

其中，这是一个sigmoid函数，可以输出(0,1)区间的数值，表示某一组特征值属于某一类的概率，$`\omega`$表示的是模型的参数矩阵，$`x`$表示的是模型的特征值矩阵，而P表示的是模型在给定特征x的条件下，模型属于正类(y=1)的概率；

sigmoid函数的大致图像如下，可以看到它输出(0,1)区间的数值，适合表示概率，通过改变x的系数可以改变图像的“宽度”；

<img src="./imgs/001.png" alt="001" style="zoom: 67%;" />

**【模型损失函数】**

逻辑回归的损失函数是对数损失，也被称为**交叉熵损失**，表示为：

```math
L = -\frac{1}{N} \sum_{i=1}^{N} \left[ y_i \log(\hat{p}_i) + (1 - y_i) \log(1 - \hat{p}_i) \right]
```

其中，$`y_{i}`$表示真实标签（0/1），$`\hat{p_{i}} `$表示模型预测样本属于正类的概率，N是样本数量；

该损失函数由似然函数推导而来，似然函数：

```math
L(\omega )=\prod_{i=1}^{N}([p(x_{i})]^{y_{i}}[1-p(x_{i})]^{1-y_{i}}) 
```

要将函数的幂进行处理，并将累乘变为累加，我们需要对函数两边取对数，得到：



## 公式分析及推导

## 代码实现