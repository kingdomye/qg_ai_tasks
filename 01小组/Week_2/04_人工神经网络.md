# äººå·¥ç¥ç»ç½‘ç»œ

Written by ricckker 2025/3/27 GuangdongÂ·Guangzhou

## å¼•å…¥

åœ¨æ­£å¼ä»‹ç»äººå·¥ç¥ç»ç½‘ç»œä¹‹å‰ï¼Œæˆ‘è®¤ä¸ºé¦–å…ˆä»‹ç»ä¸€ä¸‹ç”Ÿç‰©ç¥ç»å…ƒçš„ç»“æ„æ˜¯ä¸€ä¸ªå¾ˆä¸é”™çš„é€‰æ‹©ï¼Œè¿™å°†æ˜¯ä¸€ä¸ªéå¸¸æœ‰è¶£çš„å†…å®¹ï¼Œä¹Ÿæœ‰åŠ©äºæˆ‘ä»¬åé¢æ›´åŠ å½¢è±¡çš„è®°å¿†äººå·¥ç¥ç»ç½‘ç»œçš„åŸç†ï¼›

<img src="../../img/013.png" alt="013" style="zoom:50%;" />

å¦‚å›¾ï¼Œè¿™æ˜¯ä¸€ä¸ªç”Ÿç‰©ç¥ç»å…ƒç»“æ„ï¼Œç”±å›¾ä¸­æ‰€ç¤ºçš„å„ä¸ªéƒ¨åˆ†æ„æˆï¼Œå½“æˆ‘ä»¬çš„å¤§è„‘åœ¨è¿›è¡Œæ€è€ƒçš„æ—¶å€™ï¼Œç¥ç»å…ƒä¼šç»å†ä¸€ç³»åˆ—å¤æ‚çš„ç”Ÿç†å’Œç”µç”Ÿç†è¿‡ç¨‹ï¼Œè¿™äº›è¿‡ç¨‹å…±åŒæ„æˆäº†å¤§è„‘çš„ä¿¡æ¯å¤„ç†å’Œè®¤çŸ¥åŠŸèƒ½ï¼›å½“å¤§è„‘æ¥å—å¤–éƒ¨åˆºæ¿€æ—¶ï¼Œæ¯”å¦‚ricckkeråŒå­¦åœ¨æ€æ”¿è¯¾ä¸Šå†™QGä½œä¸šçªç„¶è¢«è€å¸ˆä¸€æ‹æ¡Œå­ï¼Œricckkerçš„ç¥ç»å…ƒå°†ä¼šæ¥å—å¤–éƒ¨åˆºæ¿€ï¼Œåˆºæ¿€è½¬åŒ–ä¸ºç”Ÿç‰©ç”µä¿¡å·ï¼Œå½“æŸä¸ªç¥ç»å…ƒè¢«æ¿€æ´»æ—¶ï¼Œä¿¡å·é€šè¿‡çªè§¦ä¼ æ’­è‡³ç¥ç»æœ«æ¢¢ï¼Œä¸å…¶ä»–ç¥ç»å…ƒä¸Šçš„å—ä½“ç»“åˆï¼Œä»è€Œå¼•å‘ä¸‹ä¸€ä¸ªç¥ç»å…ƒçš„ç”µä½å˜åŒ–ï¼Œäºæ˜¯ï¼Œricckkerçš„å¤§è„‘æœ€ç»ˆæ¥æ”¶åˆ°äº†èµ¶ç´§æ”¶èµ·ç”µè„‘çš„ä¿¡å·ï¼Œå®Œæˆäº†å…³ç”µè„‘çš„æ“ä½œï¼›é‚£ä¹ˆä»¥ä¸Šå°±æ˜¯ç”Ÿç‰©ç¥ç»å…ƒçš„ä¸€ä¸ªåŸºæœ¬å·¥ä½œåŸç†ï¼›æˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ ‘çªã€çªè§¦å’Œç¥ç»æœ«æ¢¢åœ¨ä¿¡å·ä¼ æ’­çš„è¿‡ç¨‹ä¸­èµ·åˆ°äº†å…³é”®ä½œç”¨ã€‚

## äººå·¥ç¥ç»ç½‘ç»œä»‹ç»

äººå·¥ç¥ç»ç½‘ç»œï¼ˆArtificial Neural Networck ANNï¼‰ä½œä¸ºæœºå™¨å­¦ä¹ çš„ä¸€ä¸ªéƒ¨åˆ†ï¼Œæ˜¯ä¸€ç§æ¨¡ä»¿ç”Ÿç‰©ç¥ç»ç½‘ç»œçš„ç»“æ„å’ŒåŠŸèƒ½çš„è®¡ç®—æ¨¡å‹ï¼Œå®ƒé€šè¿‡å¤§é‡çš„ç®€å•å¤„ç†å•å…ƒï¼ˆäººå·¥ç¥ç»å…ƒï¼‰ç›¸äº’è¿æ¥æ¥å®ç°ä¿¡æ¯å¤„ç†å’Œå­¦ä¹ ï¼›æ ¹æ®å‰é¢å¯¹ç”Ÿç‰©ç¥ç»å…ƒçš„ä»‹ç»ï¼Œæˆ‘ä»¬å¯ä»¥å°†å…¶ç®€åŒ–ä¸ºä¸€ä¸ªç®€å•çš„æ•°å­¦æ¨¡å‹ï¼š

<img src="../../img/014.png" alt="014" style="zoom:50%;" />

è¿™æ˜¯ä¸€ä¸ªç®€å•çš„äººå·¥ç¥ç»å…ƒæ¨¡å‹ï¼Œä¹Ÿå°±æ˜¯å¤šä¸ªè¾“å…¥ï¼Œé€šè¿‡æ¿€æ´»å‡½æ•°å¾—åˆ°ä¸€ä¸ªè¾“å‡ºï¼Œè¯¥ç¥ç»å…ƒä¸å…¶ä»–ç¥ç»å…ƒç›¸è¿ï¼Œå°†è¾“å‡ºä¼ é€’åˆ°ä¸‹ä¸€ä¸ªç¥ç»å…ƒä½œä¸ºè¾“å…¥ï¼Œä»¥æ­¤ç±»æ¨ï¼Œäºæ˜¯å¤šä¸ªç¥ç»å…ƒåœ¨ä¸€èµ·ä¾¿æ„å»ºäº†å±‚ï¼Œå¤šä¸ªå±‚åœ¨ä¸€èµ·ä¾¿æ„å»ºäº†ä¸€ä¸ªäººå·¥ç¥ç»ç½‘ç»œï¼ˆANNï¼‰ã€‚é‚£ä¹ˆï¼Œæˆ‘ä»¬å°±å¯ä»¥é€šè¿‡ä»£ç å®ç°ä¸€ä¸ªæœ€ç®€å•çš„ANNæ¨¡å‹ï¼Œæˆ‘ä»¬å…ˆä»åŸºæœ¬å•ä½ç¥ç»å…ƒå…¥æ‰‹ï¼š

```python
class Neuron:
    def __init__(self):
        self.inputs = None  # ç¥ç»å…ƒçš„è¾“å…¥
        self.f = None       # ç¥ç»å…ƒæ¿€æ´»å‡½æ•°
        self.output = None  # ç¥ç»å…ƒçš„è¾“å‡º

    def get_output(self):
        self.output = self.f(self.inputs)
        return self.output
    
```

åœ¨æ„å»ºç¥ç»å…ƒçš„åŒæ—¶ï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ªget_outputæ–¹æ³•ç”¨äºè®¡ç®—ç¥ç»å…ƒçš„è¾“å‡ºï¼Œé‚£ä¹ˆå°†å¤šä¸ªç¥ç»å…ƒæ”¾åœ¨ä¸€èµ·æˆ‘ä»¬å°±å¾—åˆ°äº†å±‚ï¼š

```python
class Layer:
    def __init__(self, num_neurons, f):
        self.neurons = [Neuron() for _ in range(num_neurons)]
        self.f = f

    def get_outputs(self):
        return [neuron.get_output() for neuron in self.neurons]
```

å°†å±‚ä¸å±‚ç›¸äº’è¿æ¥ï¼Œè¿™æ ·ä½ å°±å¾—åˆ°äº†ä¸€ä¸ªäººå·¥ç¥ç»ç½‘ç»œï¼

```python
class Network:
    def __init__(self, layers):
        self.layers = layers

```

å½“ç„¶è¿™åªæ˜¯ä¸€ä¸ªæœ€åŸºç¡€çš„æ¨¡å‹ï¼Œå®ƒä¼¼ä¹è¿˜ä¸èƒ½å®Œæˆä»»ä½•å·¥ä½œï¼Œæˆ‘ä»¬è¿˜éœ€è¦å¯¹å…¶è¿›è¡Œç ”ç©¶å’Œæ¢ç´¢æ‰èƒ½å®Œå–„å®ƒã€‚

## äººå·¥ç¥ç»ç½‘ç»œç»“æ„

ä¸€èˆ¬æ¥è¯´ï¼Œäººå·¥ç¥ç»ç½‘ç»œå…±æœ‰ä¸‰å¤§éƒ¨åˆ†ç»„æˆï¼Œåˆ†åˆ«ä¸ºï¼šè¾“å…¥å±‚ï¼Œéšè—å±‚å’Œè¾“å‡ºå±‚ï¼›ä¾‹å¦‚å¯¹äºæ‰‹å†™æ•°å­—æ•°æ®é›†ï¼Œæˆ‘ä»¬å°†æ‰‹å†™æ•°å­—è½¬åŒ–ä¸ºè¾“å…¥å±‚çš„ä¿¡å·ï¼Œä¿¡å·åœ¨éšè—å±‚ä¸­å±‚å±‚ä¼ æ’­ï¼Œæœ€ååˆ°è¾¾è¾“å‡ºå±‚ï¼Œè¾“å‡ºæœ€å¯èƒ½çš„æ•°å­—ï¼Œä»è¿™ä¸ªä¾‹å­æˆ‘ä»¬å¯ä»¥çŸ¥é“ï¼Œè¾“å…¥å±‚å’Œè¾“å‡ºå±‚åªæœ‰ä¸€å±‚ï¼Œè€Œéšè—å±‚å¯ä»¥æœ‰å¾ˆå¤šå±‚ï¼Œæ•°æ®ä»è¾“å…¥å±‚é€å±‚ä¼ æ’­åˆ°è¾“å‡ºå±‚çš„è¿‡ç¨‹æˆ‘ä»¬ç§°ä¹‹ä¸º<å‰å‘ä¼ æ’­>ï¼›æˆ‘ä»¬å¯ä»¥æŠŠç¥ç»ç½‘ç»œçœ‹ä½œæ˜¯ä¸€ä¸ªé»‘ç®±ï¼Œè¾“å…¥å›¾ç‰‡ï¼Œç»è¿‡ä¸€å †å¤æ‚çš„å‡½æ•°å¤„ç†ï¼Œæœ€åè¾“å‡ºä¸€ä¸ªæ•°å­—è¡¨ç¤ºå›¾ç‰‡ä»£è¡¨çš„å¯èƒ½æ•°å­—ï¼š

<img src="../../img/015.png" alt="015" style="zoom:50%;" />

è¿™å°±æ˜¯äººå·¥ç¥ç»ç½‘ç»œåšçš„å·¥ä½œï¼Œæˆ‘ä»¬å¯ä»¥æŠŠå®ƒçœ‹ä½œä¸€ä¸ªå¾ˆå¤æ‚çš„å‡½æ•°ï¼Œé€šè¿‡ä¸åŒçš„è®­ç»ƒï¼Œå®ƒå°±èƒ½å¯¹åº”çš„å®Œæˆä¸åŒçš„åŠŸèƒ½ï¼›

<img src="../../img/016.png" alt="016" style="zoom:50%;" />

## ç¥ç»å…ƒå·¥ä½œåŸç†

å‰é¢ç¨å¾®ä»‹ç»äº†ç¥ç»å…ƒçš„å·¥ä½œåŸç†ï¼Œè¿™é‡Œæˆ‘ä»¬è¯¦ç»†ä»‹ç»ä¸€ä¸‹å®ƒçš„æ•°å­¦åŸç†ï¼›

æˆ‘ä»¬å¯ä»¥å°†ç¥ç»å…ƒçš„æ¯ä¸€ä¸ªè¾“å…¥æ•°æ®éƒ½è½¬æ¢æˆæ•°å­—ç±»å‹æ•°æ®ï¼Œè¿™æ ·å°±å¯ä»¥æ–¹ä¾¿æˆ‘ä»¬å¯¹å…¶è¿›è¡Œè®¡ç®—ï¼Œå¯¹äºæ¯ä¸€ä¸ªè¾“å…¥çš„æ•°æ®ï¼Œæˆ‘ä»¬å°†å…¶ä¹˜ä¸Šå¯¹åº”çš„æƒé‡ï¼Œæœ€åå°†æ¯ä¸€ä¸ªæ•°æ®ç›¸åŠ ï¼Œé€šè¿‡æ¿€æ´»å‡½æ•°åè¾“å‡ºï¼›

ã€ä¸ºä»€ä¹ˆè¦ä¹˜ä»¥æƒé‡ã€‘æƒ³è±¡æˆ‘ä»¬äººè„‘å¯¹æŸä¸€ä¸ªæ‰‹å†™æ•°å­—è¿›è¡Œè¯†åˆ«çš„è¿‡ç¨‹ï¼Œæˆ‘ä»¬ä¹‹æ‰€ä»¥èƒ½åŒºåˆ†ä¸åŒçš„æ‰‹å†™æ•°å­—ï¼Œå› ä¸ºä»–ä»¬åœ¨å½¢çŠ¶ä¸Šæœ‰æ‰€å·®å¼‚ï¼Œä½†æ˜¯èƒŒåçš„è®°å¿†æœºåˆ¶æ˜¯å¦‚ä½•çš„ï¼Ÿæˆ‘ä»¬é€šè¿‡åˆ¤æ–­æ•°å­—å½¢çŠ¶çš„æŸäº›ç‰¹å¾ï¼Œä¾‹å¦‚æ•°å­—â€œ1â€å’Œâ€œ8â€ï¼Œåœ¨æŸä¸€éƒ¨åˆ†æ•°å­—â€œ8â€æ‰€å çš„æ¯”ä¾‹è¶Šé«˜ï¼Œæ‰€ä»¥å½“å›¾ç‰‡ä¿¡å·ä¼ å…¥æˆ‘ä»¬äººè„‘æ—¶ï¼Œå®ƒæ‰€å¯¹åº”çš„éƒ¨åˆ†æƒé‡ä¹Ÿå°±è¶Šé«˜ï¼Œæœ€åç¥ç»ç½‘ç»œè¾“å‡º8çš„æœºç‡ä¹Ÿæ›´é«˜ï¼Œæœ‰äº†æƒé‡ï¼Œå¹¶åœ¨è®°å¿†ä¸­ä¸æ–­è°ƒæ•´ï¼Œè¿™å°±æ˜¯ç¥ç»å…ƒæ˜¯å¦‚ä½•è®°å¿†æŸäº›æ•°æ®çš„åŸºæœ¬åŸç†ã€‚

æˆ‘ä»¬è®¾ç¥ç»å…ƒæ¥å—è¿™æ ·çš„ä¸€ç»„è¾“å…¥ï¼š

```math
\mathbf{x}  =(x_{1},x_{2},...,x_{n})
```

å¯¹åº”çš„æƒé‡å‘é‡ä¸ºï¼š

```math
\mathbf{\omega }  =(\omega_{1},\omega_{2},...,\omega_{n})
```

å°†ä¸¤ç»„å‘é‡ç‚¹ä¹˜ï¼Œé€šè¿‡æ¿€æ´»å‡½æ•°åå¾—åˆ°ç¥ç»å…ƒçš„è¾“å‡ºï¼š

```math
output=f(\mathbf{xÂ·\omega } )=f(\sum_{i=1}^{n}x_{i}\omega _{i} )
```

`f`å°±è¡¨ç¤ºç¥ç»å…ƒçš„æ¿€æ´»å‡½æ•°ã€‚

## æ¿€æ´»å‡½æ•°

ç°åœ¨æˆ‘ä»¬ä»‹ç»å‡ ä¸ªå¸¸è§çš„æ¿€æ´»å‡½æ•°

ã€ä¸ºä»€ä¹ˆè¦ä½¿ç”¨æ¿€æ´»å‡½æ•°ï¼Ÿã€‘æ¿€æ´»å‡½æ•°æ˜¯ä¸€ä¸ªéçº¿æ€§å‡½æ•°ï¼Œèƒ½å¤Ÿä½¿ç¥ç»ç½‘ç»œä»»æ„é€¼è¿‘ä»»ä½•éçº¿æ€§å‡½æ•°ï¼Œè‹¥æ²¡æœ‰æ¿€æ´»å‡½æ•°ï¼Œé‚£ä¹ˆæ— è®ºç¥ç»ç½‘ç»œæœ‰å¤šå°‘å±‚ï¼Œæœ€ç»ˆéƒ½åªæ˜¯è¾“å…¥æ•°æ®çš„çº¿æ€§ç»„åˆï¼Œè¿™å°±é€€åŒ–åˆ°æ„ŸçŸ¥å™¨æ¨¡å‹äº†ï¼Œå¤„ç†èƒ½åŠ›è‡ªç„¶å°±è¢«å¼±åŒ–äº†ã€‚

### sigmoidå‡½æ•°

```math
f(x)=\frac{1}{1+e^{-x}}
```

<img src="../../img/017.png" alt="017" style="zoom:50%;" />

ä»¥ä¸Šå°±æ˜¯sigmoidå‡½æ•°çš„æ•°å­¦è¡¨è¾¾å¼ä»¥åŠå‡½æ•°å›¾åƒï¼Œæˆ‘ä»¬å¯ä»¥å‘ç°ï¼Œsigmoidå‡½æ•°çš„è¾“å‡ºèŒƒå›´æ˜¯0ï½1ï¼Œéå¸¸é€‚åˆè¡¨ç¤ºæŸä¸ªäº‹ä»¶çš„æ¦‚ç‡

### Tanhå‡½æ•°

```math
f(x)=\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}
```

<img src="../../img/018.png" alt="018" style="zoom:50%;" />

tanhæ˜¯ä¸€ä¸ªå…³äºåŸç‚¹å¯¹ç§°çš„å›¾å½¢ï¼Œè¾“å‡ºçš„èŒƒå›´æ˜¯-1ï½1ï¼Œåœ¨å®é™…åº”ç”¨ä¸­ï¼Œtanhçš„æ•ˆæœä¼šæ¯”sigmoidè¾ƒå¥½

### ReLUå‡½æ•°

```math
f(x)=max(0,x)
```

<img src="../../img/019.png" alt="019" style="zoom:50%;" />

ReLUå‡½æ•°ä¹Ÿæ˜¯ä¸€ä¸ªé‡è¦ä¸”å¸¸è§çš„æ¿€æ´»å‡½æ•°ï¼Œå®ƒè§£å†³äº†æ¢¯åº¦æ¶ˆå¤±çš„é—®é¢˜ï¼Œå½“è¾“å…¥å€¼ä¸ºæ­£æ—¶ï¼Œç¥ç»å…ƒä¸ä¼šé¥±å’Œï¼Œå…·ä½“æ•ˆæœå¯ä»¥åœ¨å®é™…åº”ç”¨ä¸­æœ‰æ˜æ˜¾ä½“ç°ã€‚

------

å½“ç„¶ï¼Œäººå·¥ç¥ç»å…ƒè¿˜æœ‰å¾ˆå¤šæ¿€æ´»å‡½æ•°ï¼Œä»¥ä¸Šä»‹ç»çš„åªæ˜¯å…¶ä¸­æœ€å¸¸è§çš„ï¼Œæœ‰å…³å…¶ä»–æ¿€æ´»å‡½æ•°ï¼Œæœ‰å„è‡ªçš„ä¼˜åŠ¿å’ŒåŠ£åŠ¿ï¼Œéœ€è¦æ ¹æ®å®é™…æƒ…å¢ƒé€‰æ‹©åˆé€‚çš„æ¿€æ´»å‡½æ•°ï¼Œæ‰èƒ½è®­ç»ƒå‡ºä¸€ä¸ªè¾ƒå¥½çš„æ¨¡å‹

## ANNå·¥ä½œæœºåˆ¶

å‰é¢å·²ç»ä»‹ç»äº†æœ‰å…³ANNçš„åŸºç¡€çŸ¥è¯†ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬çœ‹çœ‹äººå·¥ç¥ç»ç½‘ç»œæ˜¯å¦‚ä½•è¢«è®­ç»ƒçš„ï¼›ç±»ä¼¼äºäººè„‘çš„è®°å¿†æœºåˆ¶ï¼Œä¾‹å¦‚é’ˆå¯¹æˆ‘ä»¬åœ¨è¯†å­—æ—¶ï¼Œéœ€è¦é€šè¿‡åå¤è®°å¿†ã€å­¦ä¹ æˆ‘ä»¬å°±è®°ä½äº†è¿™ä¸ªå­—ï¼Œå½“æˆ‘ä»¬çœ‹åˆ°æŸä¸ªå­—æ—¶ï¼Œäººè„‘çš„ç¥ç»ç½‘ç»œå¼€å§‹å·¥ä½œï¼Œä½†æ˜¯è®°å¿†æœºåˆ¶æœ‰åˆ«äºå‰é¢æ‰€ä»‹ç»çš„å‰å‘ä¼ æ’­ï¼Œæˆ‘ä»¬æ˜¯åœ¨çŸ¥é“å­—æ˜¯ä»€ä¹ˆå­—çš„å‰æä¸‹å¯¹å…¶è¿›è¡Œè®°å¿†ï¼Œæˆ–è€…æ¢å¥è¯è¯´ï¼Œè¿™æ˜¯ä¸€ä¸ªè¢«æ‰“ä¸Šæ ‡ç­¾çš„æ•°æ®ï¼Œæˆ‘ä»¬æœ€ç»ˆè®°å¿†äº†æ•°æ®ä¸è¯¥æ ‡ç­¾æ˜¯ç›¸å¯¹åº”çš„ï¼Œè¿™æ—¶å°±è¦å¼•å…¥<åå‘ä¼ æ’­>çš„æ¦‚å¿µäº†ï¼Œç¥ç»ç½‘ç»œé€šè¿‡åå‘ä¼ æ’­ï¼Œé€æ­¥è°ƒæ•´æ¯ä¸€å±‚ç¥ç»å…ƒçš„æƒé‡ï¼Œä½¿å¾—è¯¥æ•°æ®åœ¨å‰å‘ä¼ æ’­æ—¶èƒ½å¤Ÿæ­£ç¡®è¾“å‡ºå¯¹åº”çš„æ ‡ç­¾ã€‚

### åå‘ä¼ æ’­ç®—æ³•(BPç®—æ³•)

è°ƒæ•´ç¥ç»ç½‘ç»œçš„æƒé‡ä¸»è¦ä¾é åå‘ä¼ æ’­ç®—æ³•å®ç°ï¼Œåå‘ä¼ æ’­ç®—æ³•ä¹Ÿç§°ä¸ºâ€œè¯¯å·®åå‘ä¼ æ’­â€ç®—æ³•ï¼Œæ˜¯é€‚åˆäºå¤šå±‚ç¥ç»ç½‘ç»œçš„ä¸€ç§å­¦ä¹ ç®—æ³•ï¼Œå®ƒå»ºç«‹åœ¨æ¢¯åº¦ä¸‹é™æ³•çš„åŸºç¡€ä¸Šï¼Œæ¢¯åº¦ä¸‹é™æ³•é€šè¿‡è®¡ç®—æŸå¤±å‡½æ•°çš„æ¢¯åº¦ï¼Œå¹¶å°†æ¢¯åº¦åé¦ˆç»™æœ€ä¼˜åŒ–å‡½æ•°æ¥æ›´æ–°æƒé‡ä»¥æœ€å°åŒ–æŸå¤±å‡½æ•°ã€‚

é¦–å…ˆæˆ‘ä»¬ä»‹ç»ç½‘ç»œçš„è¯¯å·®ï¼Œå®šä¹‰è¾“å‡ºè¯¯å·®ä¿¡å·ä¸ºï¼š

```math
e_{j}=d_{j}(n)-y_{j}(n)
```

å…¶ä¸­ç¥ç»å…ƒ`j`æ˜¯è¾“å‡ºèŠ‚ç‚¹ï¼Œå®šä¹‰ç¥ç»å…ƒ`j`çš„æŸå¤±å‡½æ•°ï¼š

```math
E(n)=\frac{1}{2}\sum_{j\in C}^{} e_{j}^{2}(n)
```

é›†åˆ`C`åŒ…æ‹¬ç½‘ç»œè¾“å‡ºå±‚çš„æ‰€æœ‰ç¥ç»å…ƒï¼Œå¯¹æ‰€æœ‰næ±‚å’Œï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°ç½‘ç»œçš„å‡æ–¹è¯¯å·®(MSE)ï¼š

```math
E_{av}=\frac{1}{N}\sum_{n=1}^{N}E(n)
```

è®­ç»ƒæ¨¡å‹çš„ç›®çš„å°±æ˜¯é€šè¿‡è°ƒæ•´ç½‘ç»œä¸­æ¯ä¸ªç¥ç»å…ƒçš„æƒé‡å‚æ•°æœ€å°åŒ–è¿™ä¸ªæŸå¤±å‡½æ•°ï¼Œç±»ä¼¼äºå¤šå…ƒçº¿æ€§å›å½’æ±‚è§£å‚æ•°çš„è¿‡ç¨‹ï¼Œå¯¹äºç¥ç»å…ƒçš„å‚æ•°æ›´æ–°ï¼Œæˆ‘ä»¬åŒæ ·ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ³•ï¼š

```math
\omega_{k+1}=\omega_{k}-\alphaÂ·grad
```

```math
è®°ç¥ç»å…ƒjåœ¨è¿­ä»£næ¬¡è¾“å‡ºçš„å‡½æ•°ä¿¡å·ä¸ºy_{j}(n)=f(\sum_{i=0}^{m}\omega_{jk}(n)y_{i}(n))
```

å…¶ä¸­ï¼Œ$`\omega_{jk}`$è¡¨ç¤ºæƒé‡ï¼Œ$`y_{i}`$è¡¨ç¤ºä¸Šä¸€å±‚çš„è¾“å‡ºï¼Œ`f`è¡¨ç¤ºæ¿€æ´»å‡½æ•°

```math
grad=\frac{\partial E(n)}{\partial \omega_{jk}(n)}=\frac{\partial E(n)}{\partial e_{j}(n)}Â·\frac{\partial e_{j}(n)}{\partial y_{j}(n)} Â·\frac{\partial y_{j}(n)}{\partial v_{j}(n)}Â·\frac{\partial v_{j}(n)}{\partial \omega_{jk}(n)} 
```

æˆ‘ä»¬é€ä¸€æ±‚è§£å¼å­ä¸­çš„æ¯ä¸€é¡¹ï¼š

```math
\frac{\partial E(n)}{\partial e_{j}(n)}=e_{j}(n)
```

```math
\frac{\partial e_{j}(n)}{\partial y_{j}(n)}=\frac{\partial (d_{j}(n)-y_{j}(n))}{\partial y_{j}(n)}=-1
```

```math
\frac{\partial y_{j}(n)}{\partial v_{j}(n)}=f'_{j}(\sum_{i=0}^{m}\omega_{jk}(n)y_{i}(n))
```

```math
\frac{\partial v_{j}(n)}{\partial \omega_{jk}(n)} =\frac{\partial \sum_{i=0}^{m}\omega_{jk}(n)y_{i}(n)}{\partial \omega_{jk}(n)}=y_{i}(n)
```

```math
grad=-e_{j}(n)f'_{j}(\sum_{i=0}^{m}\omega_{jk}(n)y_{i}(n))y_{i}(n)
```

```math
ä»¤\delta _{j}(n)=-\frac{\partial E}{\partial v_{j}(n)}=-e_{j}(n)f'_{j}(\sum_{i=0}^{m}\omega_{jk}(n)y_{i}(n)) 
```

```math
åˆ™grad=\alphaÂ·\delta _{j}(n)Â·y_{j}(n)
```

ä»¥ä¸Šæ˜¯å¯¹è¾“å‡ºå±‚çš„æƒé‡ä¿®æ­£å…¬å¼ï¼Œä¸‹é¢æ¥æ¨å¯¼éšè—å±‚çš„æ¢¯åº¦ä¸‹é™å…¬å¼ï¼š

å½“ç¥ç»å…ƒ`j`ä½äºéšè—å±‚æ—¶ï¼Œæ²¡æœ‰æœŸæœ›çš„è¾“å‡ºï¼Œæˆ‘ä»¬å°±è¦ä¿®æ”¹å…¬å¼ï¼š

```math
\delta _{j}(n)=-\frac{\partial E}{\partial y_{j}(n)}Â·\frac{\partial y_{j}(n)}{\partial v_{j}(n)} =-\frac{\partial E}{\partial y_{j}(n)}f'_{j}(\sum_{i=0}^{m}\omega_{jk}(n)y_{i}(n))
```

```math
\frac{\partial E}{\partial y_{j}(n)}=\frac{1}{2}Â·\frac{\sum_{k\in C}^{} e_{k}^{2}(n)}{\partial y_{j}(n)}=\sum_{k}^{}e_{k}(n)\frac{\partial e_{k}(n)}{\partial y_{j}(n)}=\sum_{k}^{}e_{k}(n)\frac{\partial e_{k}(n)}{\partial v_{k}(n)} Â·\frac{\partial v_{k}(n)}{\partial y_{j}(n)} 
```

```math
=-\sum_{k} e_{k}(n)f'(\sum_{i=0}^{m}\omega_{jk}(n)y_{i}(n))w_{kj}(n)=-\sum _{k}\delta_{k}(n)w_{kj}(n)
```

```math
äºæ˜¯\delta _{j}(n)=f'(\sum_{i=0}^{m}\omega_{jk}(n)y_{i}(n))\sum _{k}\delta _{k}(n)w_{kj}(n)
```

## ç†è®ºå­˜åœ¨ï¼Œå®è·µå¼€å§‹

æ¥ä¸‹æ¥æˆ‘ä»¬ç”¨ä»£ç å®ç°äººå·¥ç¥ç»ç½‘ç»œçš„æ¨¡å‹è®­ç»ƒï¼Œæˆ‘ä»¬å¯èƒ½éœ€è¦é‡æ–°å®šä¹‰ç¥ç»å…ƒï¼Œå®ç°æ›´åŠ é«˜æ•ˆçš„æ“ä½œ

é¦–å…ˆå¯¼å…¥å¿…è¦çš„åº“å’Œå®šä¹‰å¿…è¦çš„å‡½æ•°

```python
import numpy as np
from matplotlib import pyplot as plt

def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def sigmoid_derivative(x):
    return x * (1 - x)

def relu(x):
    return np.maximum(0, x)

def relu_derivative(x):
    return 1. * (x > 0)

def tanh(x):
    return np.tanh(x)

def tanh_derivative(x):
    return 1 - np.tanh(x) ** 2
```

é‡æ–°å®šä¹‰ç¥ç»å…ƒ

```python
class Neuron:
    def __init__(self, weights, f):
        self.inputs = None  # ç”¨äºå­˜å‚¨è¾“å…¥å€¼
        self.weights = weights
        self.output = 0
        self.delta = 0  # ç”¨äºå­˜å‚¨è¯¯å·®åå‘ä¼ æ’­æ—¶çš„æ¢¯åº¦
        self.f = f  # æ¿€æ´»å‡½æ•°

    def forward(self, inputs):
        self.inputs = inputs
        self.output = self.f(np.dot(inputs, self.weights))
        return self.output
```

æ„å»ºå±‚ï¼š

```python
class Layer:
    def __init__(self, num_inputs, num_neurons, f):
        self.neurons = [Neuron(np.random.uniform(-1, 1, num_inputs), f) for _ in range(num_neurons)]
        self.output = []
        self.delta = []  # ç”¨äºå­˜å‚¨è¿™ä¸€å±‚çš„è¯¯å·®

    def forward(self, inputs):
        self.output = np.array([neuron.forward(inputs) for neuron in self.neurons])
        return self.output
```

æ„å»ºANNç½‘ç»œï¼š

```python
class ANN:
    def __init__(self, layers):
        self.layers = layers

    def forward(self, inputs):
        for layer in self.layers:
            inputs = layer.forward(inputs)
        return inputs
```

ä¸Šé¢çš„ä»£ç å®ç°éƒ½ç›¸å¯¹å®¹æ˜“ï¼Œä¸‹é¢é‡ç‚¹æ¥çœ‹åå‘ä¼ æ’­backwardçš„ç®—æ³•ï¼Œé’ˆå¯¹è¾“å‡ºå±‚å’Œéšè—å±‚ï¼Œæˆ‘ä»¬éœ€è¦è®¾è®¡ä¸åŒçš„ç®—æ³•å®ç°ä¸åŒçš„$`\delta`$è®¡ç®—ï¼Œä»£ç å˜é‡è¾ƒå¤šæœ‰ç‚¹ç»•ï¼Œéœ€è¦ä»”ç»†æ€è€ƒã€è®¤çœŸè§‚å¯Ÿä»£ç ï¼

```python
    def backward(self, expected, learning_rate):
        for i in reversed(range(len(self.layers))):
            layer = self.layers[i]
            
            # è¾“å‡ºå±‚deltaè®¡ç®—
            if i == len(self.layers) - 1:
                for j in range(len(layer.neurons)):
                    neuron = layer.neurons[j]
                    neuron.delta = (expected[j] - neuron.output) * sigmoid_derivative(neuron.output)
            
            # éšè—å±‚deltaè®¡ç®—
            else:
                for j in range(len(layer.neurons)):
                    neuron = layer.neurons[j]
                    neuron.delta = 0
                    for k in range(len(self.layers[i + 1].neurons)):
                        neuron.delta += self.layers[i + 1].neurons[k].delta * self.layers[i + 1].neurons[k].weights[j]
                    neuron.delta *= sigmoid_derivative(neuron.output)
            
            # æ›´æ–°æƒé‡
            for j in range(len(layer.neurons)):
                neuron = layer.neurons[j]
                for k in range(len(neuron.weights)):
                    neuron.weights[k] += learning_rate * neuron.delta * neuron.inputs[k]
```

æ¨¡å‹è®­ç»ƒä»£ç ï¼š

```python
    def train(self, inputs, expected, learning_rate, epochs):
        loss_history = []
        for epoch in range(epochs):
            loss = 0
            for i in range(len(inputs)):
                self.forward(inputs[i])
                self.backward(expected[i], learning_rate)
                loss += np.mean((expected[i] - self.layers[-1].output) ** 2)
            
            loss /= len(inputs)
            loss_history.append(loss)
            
            if (epoch + 1) % 100 == 0:
                print(f'Epoch {epoch + 1}/{epochs}, Loss: {loss}')

        return loss_history
```

è‡³æ­¤ï¼Œæˆ‘ä»¬å°±å®Œæˆäº†ä¸€ä¸ªåŸºç¡€ANNçš„æ„å»ºï¼Œå®ƒå¯ä»¥ç”¨äºè®­ç»ƒå¹¶å®ŒæˆæŸäº›æ•°æ®çš„é¢„æµ‹ã€åˆ¤æ–­ï¼Œæˆ‘ä»¬æ‰‹åŠ¨ç”Ÿæˆä¸€ä¸ªæ•°æ®ï¼Œæµ‹è¯•ä¸€ä¸‹è¿™ä¸ªç½‘ç»œï¼š

```python
if __name__ == '__main__':
    # é¢„æµ‹ç®€å•çš„çº¿æ€§æ¨¡å‹
    # ç”Ÿæˆè®­ç»ƒæ•°æ®
    x = np.linspace(0, 1, 100)
    y = x + np.random.normal(0, 0.1, 100)

    inputs = x.reshape(-1, 1)
    expected = y.reshape(-1, 1)

    ann = ANN([Layer(1, 10, sigmoid), Layer(10, 5, sigmoid), Layer(5, 1, sigmoid)])
    loss_history = ann.train(inputs, expected, 0.1, 1000)

    # ç»˜åˆ¶æŸå¤±å’Œé¢„æµ‹å›¾åƒï¼Œæ‹¼åœ¨ä¸€èµ·
    plt.figure(figsize=(10, 5))
    plt.subplot(1, 2, 1)
    plt.plot(loss_history)
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Loss History')

    plt.subplot(1, 2, 2)
    plt.scatter(x, y, color='blue', label='Data')
    ann_outputs = []
    for i in range(len(inputs)):
        ann_outputs.append(ann.forward(inputs[i]))
    ann_outputs = np.array(ann_outputs)
    plt.plot(x, ann_outputs, color='red', label='Prediction')
    plt.xlabel('x')
    plt.ylabel('y')
    plt.title('Prediction')
    plt.legend()
    plt.show()
```

å…·ä½“è¾“å‡ºå¯ä»¥çœ‹Jupyterçš„è¾“å‡ºäº†ï¼Œçœ‹ä¸‹é¢çš„å›¾ç‰‡ä¹Ÿå¯ä»¥ï¼ŒåŠ è½½å¯èƒ½æ¯”è¾ƒæ…¢[å®éªŒç»“æœ](./06_ANNå®éªŒç»“æœ.ipynb)

ğŸ«µäº”æ˜Ÿä¸Šå°†â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸éº¦å…‹é˜¿ç‘Ÿè¿™æ ·è¯„ä»·é“ï¼šâ€œå½“çœ‹åˆ°è¿™æ¡å¹³æ»‘çš„è‚˜å‹MSE LINEçš„æ—¶å€™ï¼Œæˆ‘å°±çŸ¥é“ricckkerçš„æ¨¡å‹è®­ç»ƒæˆåŠŸäº†â€

<img src="../../img/020.png" alt="020" style="zoom:50%;" />
